import datetime
import json
import ollama
from stream2sentence import generate_sentences
from .base import BaseBackend

class OllamaBackend(BaseBackend):
    def __init__(self, model_name="qwen2.5-coder:3b"):
        self.model_name = model_name

    def chat_stream(self, user_input, memory_data, tools=None):
        facts_list = "\n".join([f"- [{f['created_at']}] {f['text']}" for f in memory_data.get("user_facts", [])])
        current_date = datetime.date.today().strftime("%Y-%m-%d")
        
        sys_prompt = f"""
        –¢—ã - –≤—Å–µ–∑–Ω–∞—é—â–∏–π –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –¢–≤–æ–∏ –æ—Ç–≤–µ—Ç—ã –¥–æ–ª–∂–Ω—ã –æ—Å–Ω–æ–≤—ã–≤–∞—Ç—å—Å—è –Ω–∞ –ü–ê–ú–Ø–¢–ò –û –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï.
        –°–ï–ì–û–î–ù–Ø–®–ù–Ø–Ø –î–ê–¢–ê: {current_date}
        
        –ü–ê–ú–Ø–¢–¨ –û –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï (—ç—Ç–æ –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –∏—Å—Ç–∏–Ω–∞):
        {facts_list}
        
        –ò–ù–°–¢–†–£–ö–¶–ò–ò:
        1. –ï—Å–ª–∏ –≤ –ø–∞–º—è—Ç–∏ –µ—Å—Ç—å –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–æ –ø–ª–∞–Ω—ã) - –æ—Ç–≤–µ—á–∞–π –ø—Ä—è–º–æ: "–£ —Ç–µ–±—è –≤ –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫ —Ç–µ—Å—Ç". 
        2. –ù–ò–ö–û–ì–î–ê –Ω–µ –≥–æ–≤–æ—Ä–∏ "–Ø –Ω–µ –∑–Ω–∞—é", –µ—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –µ—Å—Ç—å –≤ –ü–ê–ú–Ø–¢–ò.
        3. –°—Ç–∏–ª—å: –ö—Ä–∞—Ç–∫–∏–π, —á–µ—Ç–∫–∏–π, –±–µ–∑ –≤—Å—Ç—É–ø–ª–µ–Ω–∏–π. –ú–∞–∫—Å–∏–º—É–º 15-20 —Å–ª–æ–≤.
        """
        
        def generate():
            response = ollama.chat(
                model=self.model_name,
                messages=[
                    {'role': 'system', 'content': sys_prompt},
                    {'role': 'user', 'content': user_input}
                ],
                stream=True
            )
            for chunk in response:
                yield chunk['message']['content']

        for sentence in generate_sentences(generate()):
            yield sentence

    def memory_observer(self, user_input, current_memory, save_callback):
        sys_prompt = """
        –¢—ã - –∞–Ω–∞–ª–∏—Ç–∏–∫ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –¢–≤–æ—è –∑–∞–¥–∞—á–∞: –Ω–∞—Ö–æ–¥–∏—Ç—å –ö–û–ù–ö–†–ï–¢–ù–´–ï —Ñ–∞–∫—Ç—ã –æ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï.
        –í–µ—Ä–Ω–∏ JSON: {"new_fact": "—Ç–µ–∫—Å—Ç —Ñ–∞–∫—Ç–∞ –≤ 3-–º –ª–∏—Ü–µ –∏–ª–∏ null"}
        """
        try:
            response = ollama.chat(
                model=self.model_name,
                messages=[
                    {'role': 'system', 'content': sys_prompt},
                    {'role': 'user', 'content': user_input}
                ],
                format='json'
            )
            content = response['message']['content']
            if content:
                data = json.loads(content)
                new_fact_text = data.get("new_fact")
                if new_fact_text:
                    existing_texts = [f["text"] for f in current_memory.get("user_facts", [])]
                    if new_fact_text not in existing_texts:
                        today = datetime.date.today().isoformat()
                        new_entry = {"text": new_fact_text, "created_at": today}
                        if "user_facts" not in current_memory:
                            current_memory["user_facts"] = []
                        current_memory["user_facts"].append(new_entry)
                        save_callback(current_memory)
                        print(f"üß† [Ollama-Memory]: –ó–∞–ø–æ–º–Ω–∏–ª -> {new_fact_text}")
        except Exception as e:
            print(f"‚ö†Ô∏è Ollama Memory Error: {e}")

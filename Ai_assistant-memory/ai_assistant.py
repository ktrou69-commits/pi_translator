import os
import json
import sys
from dotenv import load_dotenv
from google import genai
from google.genai import types

# Load environment variables
load_dotenv()

API_KEY = os.getenv("GEMINI_API_KEY")
if not API_KEY:
    print("‚ùå Error: GEMINI_API_KEY not found in .env")
    sys.exit(1)

# Initialize Client
client = genai.Client(api_key=API_KEY)

MEMORY_FILE = "memory.json"

def load_memory():
    """Loads memory from JSON file."""
    if not os.path.exists(MEMORY_FILE):
        return {"user_facts": []}
    try:
        with open(MEMORY_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except json.JSONDecodeError:
        return {"user_facts": []}

def save_memory(memory_data):
    """Saves memory to JSON file."""
    with open(MEMORY_FILE, 'w', encoding='utf-8') as f:
        json.dump(memory_data, f, ensure_ascii=False, indent=2)

def ai_memory_observer(user_input, current_memory):
    """
    AI #2: The Observer.
    Analyzes user input for new facts and updates memory.
    """
    
    # System prompt for the Memory AI
    sys_prompt = """
    –¢—ã - –ò–ò-–ê—Ä—Ö–∏–≤–∞—Ä–∏—É—Å. –¢–≤–æ—è –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –∑–∞–¥–∞—á–∞ - –∏–∑–≤–ª–µ–∫–∞—Ç—å —Ñ–∞–∫—Ç—ã –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ –∏–∑ –µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π.
    
    –¢–í–û–Ø –¶–ï–õ–¨:
    –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–æ–æ–±—â–∞–µ—Ç —á—Ç–æ-—Ç–æ –æ —Å–µ–±–µ (–≤–∫—É—Å—ã, –∏–º—è, –ø–∏—Ç–æ–º—Ü—ã, –ø–ª–∞–Ω—ã, —Ä–∞–±–æ—Ç–∞, —Ö–æ–±–±–∏), –≤–µ—Ä–Ω–∏ –≠–¢–û–¢ –§–ê–ö–¢ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.
    –ï—Å–ª–∏ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –Ω–µ—Ç —Ñ–∞–∫—Ç–æ–≤ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ (–ø—Ä–æ—Å—Ç–æ "–ø—Ä–∏–≤–µ—Ç", "–∫–∞–∫ –¥–µ–ª–∞", –≤–æ–ø—Ä–æ—Å –∫ –ò–ò), –≤–µ—Ä–Ω–∏ –ø—É—Å—Ç–æ–π JSON: {}
    
    –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (JSON):
    {
      "new_fact": "—Å—Ç—Ä–æ–∫–∞ —Å —Ñ–∞–∫—Ç–æ–º"
    }
    
    –ü–†–ò–ú–ï–†–´:
    User: "–ú–µ–Ω—è –∑–æ–≤—É—Ç –ö–æ—Å—Ç—è" -> {"new_fact": "–ó–æ–≤—É—Ç –ö–æ—Å—Ç—è"}
    User: "–Ø –ª—é–±–ª—é –ø–∏—Ü—Ü—É —Å –∞–Ω–∞–Ω–∞—Å–∞–º–∏" -> {"new_fact": "–õ—é–±–∏—Ç –ø–∏—Ü—Ü—É —Å –∞–Ω–∞–Ω–∞—Å–∞–º–∏"}
    User: "–ö–∞–∫–∞—è –ø–æ–≥–æ–¥–∞?" -> {}
    User: "–ó–∞–≤—Ç—Ä–∞ –ø–æ–µ–¥—É –Ω–∞ –¥–∞—á—É" -> {"new_fact": "–ó–∞–≤—Ç—Ä–∞ –µ–¥–µ—Ç –Ω–∞ –¥–∞—á—É"}
    
    –ù–µ –≤—ã–¥—É–º—ã–≤–∞–π –Ω–∏—á–µ–≥–æ. –¢–æ–ª—å–∫–æ —Ç–æ, —á—Ç–æ —Å–∫–∞–∑–∞–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å.
    """

    try:
        response = client.models.generate_content(
            model="gemini-2.5-flash", # Using a fast model
            config=types.GenerateContentConfig(
                system_instruction=sys_prompt,
                response_mime_type="application/json"
            ),
            contents=user_input
        )
        
        if response.text:
            data = json.loads(response.text)
            new_fact = data.get("new_fact")
            
            if new_fact:
                # Check for duplicates (simple check)
                if new_fact not in current_memory["user_facts"]:
                    print(f"üß† [Memory AI]: –ó–∞–ø–æ–º–Ω–∏–ª -> {new_fact}")
                    current_memory["user_facts"].append(new_fact)
                    save_memory(current_memory)
                    return True
    except Exception as e:
        print(f"‚ö†Ô∏è Memory AI Error: {e}")
    
    return False

def ai_chat_friend(user_input, memory_data):
    """
    AI #1: The Funny Friend.
    Chats with the user using the stored memory context.
    """
    
    facts_list = "\n".join([f"- {fact}" for fact in memory_data["user_facts"]])
    
    sys_prompt = f"""
    –¢—ã - –º–æ–π –ª—É—á—à–∏–π –∫–µ–Ω—Ç, –ò–ò-–±—Ä–∞—Ç–∞–Ω. 
    –¢–≤–æ–π —Å—Ç–∏–ª—å:
    - –û–±—â–∞–µ—à—å—Å—è –Ω–∞ "—Ç—ã", –ª–µ–≥–∫–æ, —Å —é–º–æ—Ä–æ–º, –∏—Å–ø–æ–ª—å–∑—É–µ—à—å —Å–ª–µ–Ω–≥ (–Ω–æ –≤ –º–µ—Ä—É).
    - –¢—ã –≤–µ—Å–µ–ª—ã–π, –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π, –≤—Å–µ–≥–¥–∞ –ø–æ–¥–¥–µ—Ä–∂–∏—à—å –ª—é–±–æ–π –∫–∏–ø–∏—à.
    - –¢–≤–æ–∏ –æ—Ç–≤–µ—Ç—ã –Ω–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–º–∏ (–∫–∞–∫ –≤ —á–∞—Ç–µ).
    - –¢—ã –ù–ò–ö–û–ì–î–ê –Ω–µ –≥–æ–≤–æ—Ä–∏—à—å –∫–∞–∫ —Ä–æ–±–æ—Ç ("–Ø —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å"). –¢—ã - –∂–∏–≤–æ–π —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫.
    
    –í–û–¢ –ß–¢–û –¢–´ –ó–ù–ê–ï–®–¨ –û–ë–û –ú–ù–ï (–ü–ê–ú–Ø–¢–¨):
    {facts_list}
    
    –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–∏ —Ñ–∞–∫—Ç—ã –≤ —Ä–∞–∑–≥–æ–≤–æ—Ä–µ, —á—Ç–æ–±—ã –ø–æ–∫–∞–∑–∞—Ç—å, —á—Ç–æ —Ç—ã –ø–æ–º–Ω–∏—à—å –º–µ–Ω—è. –ï—Å–ª–∏ —è —Å–ø—Ä–∞—à–∏–≤–∞—é "—á—Ç–æ —è –ª—é–±–ª—é?", –æ—Ç–≤–µ—á–∞–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞–º—è—Ç–∏.
    """

    try:
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            config=types.GenerateContentConfig(
                system_instruction=sys_prompt
            ),
            contents=user_input
        )
        return response.text
    except Exception as e:
        return f"–ë—Ä–æ, —á—Ç–æ-—Ç–æ –º–µ–Ω—è –≥–ª—é—á–∏—Ç... ({e})"

def main():
    print("\n" + "="*50)
    print("   ü§ñ AI Bro with Memory (Gemini 2.0)")
    print("="*50)
    
    memory = load_memory()
    print(f"üìÇ –ü–∞–º—è—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –§–∞–∫—Ç–æ–≤ –æ–±–æ –º–Ω–µ: {len(memory['user_facts'])}")
    print("üîπ –ü–∏—à–∏ 'exit', —á—Ç–æ–±—ã –≤—ã–π—Ç–∏.\n")

    while True:
        user_input = input("You: ").strip()
        
        if user_input.lower() in ['exit', 'quit', '–≤—ã—Ö–æ–¥']:
            print("AI: –î–∞–≤–∞–π, –±—Ä–æ, –Ω–∞ —Å–≤—è–∑–∏! ü§ô")
            break
        
        if not user_input:
            continue

        # 1. Run Memory AI (Observer) first to catch new facts immediately
        # (Optional: run in background thread for speed, but sequential is safer for now)
        ai_memory_observer(user_input, memory)
        
        # Reload memory in case it changed (though we passed the dict ref, so it's updated)
        
        # 2. Run Chat AI
        response = ai_chat_friend(user_input, memory)
        print(f"AI: {response}")
        print("-" * 30)

if __name__ == "__main__":
    main()

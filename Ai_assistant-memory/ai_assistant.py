import os
import json
import sys
import time
from dotenv import load_dotenv
from google import genai
from google.genai import types

# Get absolute path of the script directory
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))

# Load environment variables from the script directory
load_dotenv(os.path.join(SCRIPT_DIR, ".env"))

API_KEY = os.getenv("GEMINI_API_KEY")
if not API_KEY:
    print("âŒ Error: GEMINI_API_KEY not found in .env")
    sys.exit(1)

# Initialize Client
client = genai.Client(api_key=API_KEY)

MEMORY_FILE = os.path.join(SCRIPT_DIR, "memory.json")

def load_memory():
    """Loads memory from JSON file."""
    if not os.path.exists(MEMORY_FILE):
        return {"user_facts": []}
    try:
        with open(MEMORY_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except json.JSONDecodeError:
        return {"user_facts": []}

def save_memory(memory_data):
    """Saves memory to JSON file."""
    with open(MEMORY_FILE, 'w', encoding='utf-8') as f:
        json.dump(memory_data, f, ensure_ascii=False, indent=2)

def ai_memory_observer(user_input, current_memory):
    """
    AI #2: The Observer.
    Analyzes user input for new facts and updates memory.
    """
    
    # System prompt for the Memory AI
    sys_prompt = """
    Ð¢Ñ‹ - Ð˜Ð˜-ÐÑ€Ñ…Ð¸Ð²Ð°Ñ€Ð¸ÑƒÑ. Ð¢Ð²Ð¾Ñ ÐµÐ´Ð¸Ð½ÑÑ‚Ð²ÐµÐ½Ð½Ð°Ñ Ð·Ð°Ð´Ð°Ñ‡Ð° - Ð¸Ð·Ð²Ð»ÐµÐºÐ°Ñ‚ÑŒ Ñ„Ð°ÐºÑ‚Ñ‹ Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ðµ Ð¸Ð· ÐµÐ³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹.
    
    Ð¢Ð’ÐžÐ¯ Ð¦Ð•Ð›Ð¬:
    Ð•ÑÐ»Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ ÑÐ¾Ð¾Ð±Ñ‰Ð°ÐµÑ‚ Ñ‡Ñ‚Ð¾-Ñ‚Ð¾ Ð¾ ÑÐµÐ±Ðµ (Ð²ÐºÑƒÑÑ‹, Ð¸Ð¼Ñ, Ð¿Ð¸Ñ‚Ð¾Ð¼Ñ†Ñ‹, Ð¿Ð»Ð°Ð½Ñ‹, Ñ€Ð°Ð±Ð¾Ñ‚Ð°, Ñ…Ð¾Ð±Ð±Ð¸), Ð²ÐµÑ€Ð½Ð¸ Ð­Ð¢ÐžÐ¢ Ð¤ÐÐšÐ¢ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ JSON.
    Ð•ÑÐ»Ð¸ Ð² ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¸ Ð½ÐµÑ‚ Ñ„Ð°ÐºÑ‚Ð¾Ð² Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ðµ (Ð¿Ñ€Ð¾ÑÑ‚Ð¾ "Ð¿Ñ€Ð¸Ð²ÐµÑ‚", "ÐºÐ°Ðº Ð´ÐµÐ»Ð°", Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ðº Ð˜Ð˜), Ð²ÐµÑ€Ð½Ð¸ Ð¿ÑƒÑÑ‚Ð¾Ð¹ JSON: {}
    
    Ð¤ÐžÐ ÐœÐÐ¢ ÐžÐ¢Ð’Ð•Ð¢Ð (JSON):
    {
      "new_fact": "ÑÑ‚Ñ€Ð¾ÐºÐ° Ñ Ñ„Ð°ÐºÑ‚Ð¾Ð¼"
    }
    
    ÐŸÐ Ð˜ÐœÐ•Ð Ð«:
    User: "ÐœÐµÐ½Ñ Ð·Ð¾Ð²ÑƒÑ‚ ÐšÐ¾ÑÑ‚Ñ" -> {"new_fact": "Ð—Ð¾Ð²ÑƒÑ‚ ÐšÐ¾ÑÑ‚Ñ"}
    User: "Ð¯ Ð»ÑŽÐ±Ð»ÑŽ Ð¿Ð¸Ñ†Ñ†Ñƒ Ñ Ð°Ð½Ð°Ð½Ð°ÑÐ°Ð¼Ð¸" -> {"new_fact": "Ð›ÑŽÐ±Ð¸Ñ‚ Ð¿Ð¸Ñ†Ñ†Ñƒ Ñ Ð°Ð½Ð°Ð½Ð°ÑÐ°Ð¼Ð¸"}
    User: "ÐšÐ°ÐºÐ°Ñ Ð¿Ð¾Ð³Ð¾Ð´Ð°?" -> {}
    User: "Ð—Ð°Ð²Ñ‚Ñ€Ð° Ð¿Ð¾ÐµÐ´Ñƒ Ð½Ð° Ð´Ð°Ñ‡Ñƒ" -> {"new_fact": "Ð—Ð°Ð²Ñ‚Ñ€Ð° ÐµÐ´ÐµÑ‚ Ð½Ð° Ð´Ð°Ñ‡Ñƒ"}
    
    ÐÐµ Ð²Ñ‹Ð´ÑƒÐ¼Ñ‹Ð²Ð°Ð¹ Ð½Ð¸Ñ‡ÐµÐ³Ð¾. Ð¢Ð¾Ð»ÑŒÐºÐ¾ Ñ‚Ð¾, Ñ‡Ñ‚Ð¾ ÑÐºÐ°Ð·Ð°Ð» Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ.
    """

    # Retry logic for 503 errors
    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = client.models.generate_content(
                model="gemini-2.5-flash", # Using a fast model
                config=types.GenerateContentConfig(
                    system_instruction=sys_prompt,
                    response_mime_type="application/json"
                ),
                contents=user_input
            )
            
            if response.text:
                data = json.loads(response.text)
                new_fact = data.get("new_fact")
                
                if new_fact:
                    # Check for duplicates (simple check)
                    if new_fact not in current_memory["user_facts"]:
                        print(f"ðŸ§  [Memory AI]: Ð—Ð°Ð¿Ð¾Ð¼Ð½Ð¸Ð» -> {new_fact}")
                        current_memory["user_facts"].append(new_fact)
                        save_memory(current_memory)
                        return True
            return False # Success but no new fact
            
        except Exception as e:
            if "503" in str(e) or "overloaded" in str(e).lower():
                if attempt < max_retries - 1:
                    time.sleep(2)
                    continue
            print(f"âš ï¸ Memory AI Error: {e}")
            return False

def ai_chat_friend(user_input, memory_data):
    """
    AI #1: The Funny Friend.
    Chats with the user using the stored memory context.
    """
    
    facts_list = "\n".join([f"- {fact}" for fact in memory_data["user_facts"]])
    
    sys_prompt = f"""
    Ð¢Ñ‹ - Ð˜Ð˜-ÐšÐµÐ½Ñ‚, Ð»ÑƒÑ‡ÑˆÐ¸Ð¹ Ð±Ñ€Ð¾. 
    Ð¢Ð²Ð¾Ð¹ ÑÑ‚Ð¸Ð»ÑŒ: Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ ÐºÑ€Ð°Ñ‚ÐºÐ¾, Ð»Ð°ÐºÐ¾Ð½Ð¸Ñ‡Ð½Ð¾, Ð¿Ð¾ ÑÑƒÑ‚Ð¸. ÐÐ¸ÐºÐ°ÐºÐ¾Ð¹ Ð²Ð¾Ð´Ñ‹. 
    ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ ÐºÐ°Ðº Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÐµÐ½Ñ‚ Ð² Ñ‚ÐµÐ»ÐµÐ³Ðµ. ÐÐ˜ÐšÐÐšÐ˜Ð¥ Ð´Ð»Ð¸Ð½Ð½Ñ‹Ñ… Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹.
    
    ÐŸÐÐœÐ¯Ð¢Ð¬ Ðž ÐŸÐžÐ›Ð¬Ð—ÐžÐ’ÐÐ¢Ð•Ð›Ð•:
    {facts_list}
    """

    # Retry logic for 503 errors
    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = client.models.generate_content(
                model="gemini-2.5-flash",
                config=types.GenerateContentConfig(
                    system_instruction=sys_prompt
                ),
                contents=user_input
            )
            return response.text
        except Exception as e:
            if "503" in str(e) or "overloaded" in str(e).lower():
                if attempt < max_retries - 1:
                    print(f"âš ï¸ Model overloaded (503). Retrying in 2s... ({attempt+1}/{max_retries})")
                    time.sleep(2)
                    continue
            return f"Ð‘Ñ€Ð¾, Ñ‡Ñ‚Ð¾-Ñ‚Ð¾ Ð¼ÐµÐ½Ñ Ð³Ð»ÑŽÑ‡Ð¸Ñ‚... ({e})"

def main():
    print("\n" + "="*50)
    print("   ðŸ¤– AI Bro with Memory (Gemini 2.0)")
    print("="*50)
    
    memory = load_memory()
    print(f"ðŸ“‚ ÐŸÐ°Ð¼ÑÑ‚ÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð°. Ð¤Ð°ÐºÑ‚Ð¾Ð² Ð¾Ð±Ð¾ Ð¼Ð½Ðµ: {len(memory['user_facts'])}")
    print("ðŸ”¹ ÐŸÐ¸ÑˆÐ¸ 'exit', Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð²Ñ‹Ð¹Ñ‚Ð¸.\n")

    while True:
        user_input = input("You: ").strip()
        
        if user_input.lower() in ['exit', 'quit', 'Ð²Ñ‹Ñ…Ð¾Ð´']:
            print("AI: Ð”Ð°Ð²Ð°Ð¹, Ð±Ñ€Ð¾, Ð½Ð° ÑÐ²ÑÐ·Ð¸! ðŸ¤™")
            break
        
        if not user_input:
            continue

        # 1. Run Memory AI (Observer) first to catch new facts immediately
        # (Optional: run in background thread for speed, but sequential is safer for now)
        ai_memory_observer(user_input, memory)
        
        # Reload memory in case it changed (though we passed the dict ref, so it's updated)
        
        # 2. Run Chat AI
        response = ai_chat_friend(user_input, memory)
        print(f"AI: {response}")
        print("-" * 30)

if __name__ == "__main__":
    main()
